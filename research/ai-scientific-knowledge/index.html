<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>
        
            AI and Scientific Knowledge - Rodrigo Dorantes Gilardi
        
    </title>
    
    
    <link rel="stylesheet" href="/scss/custom.css">
</head>
  <body>
    <nav>
    <div class="container">
      
        <a href="/">home</a>
      
        <a href="/research">research</a>
      
        <a href="/teaching">teaching</a>
      
        <a href="/post">blog</a>
      
        <a href="/cv">cv</a>
      
    </div>
  </nav>
    <main>
      
<article class="research-article">
    <div class="container">
        <header class="article-header">
            <h1>AI and Scientific Knowledge</h1>
            <div class="article-meta">
                
                    <p class="description">Auditing how large language models recognize scientific contributions.</p>
                
                <div class="tags">
                    
                        <span class="tag">Social</span>
                    
                        <span class="tag">NLP</span>
                    
                        <span class="tag">Network Science</span>
                    
                </div>
            </div>
        </header>

        <div class="article-content">
            <p>Large language models (LLMs) are rapidly becoming tools for scientific information retrieval, yet their ability to recognize scientists and their contributions is far from uniform. In this work, we audit how three leading LLMs—GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro—recognize over 100,000 physicists across the productivity spectrum.</p>
<p>Our analysis reveals systematic disparities: LLMs are significantly better at recognizing male scientists and those affiliated with Western institutions, mirroring and amplifying existing biases in scientific visibility. We trace these gaps in part to Wikipedia, which serves as a key training source and exhibits similar patterns of coverage inequality. The findings highlight that as LLMs become embedded in scientific workflows—from literature search to peer review—they risk reinforcing the unequal recognition structures already present in academia.</p>
<p>Published at <a href="https://aclanthology.org/2025.findings-emnlp.1279/" 
  
   target="_blank" rel="noreferrer noopener" 
>EMNLP, 2025</a>.</p>

        </div>

        <nav class="article-nav">
            
                <a class="prev" href="/research/inspirational-cohorts/">← Inspirational Cohorts</a>
            
            
        </nav>
    </div>
</article>

    </main>
    <footer>
    <div class="container">
      <p>© 2026 Rodrigo Dorantes Gilardi. All rights reserved.</p>
    </div>
  </footer>
  </body>
</html>